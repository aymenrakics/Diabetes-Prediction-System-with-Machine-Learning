# ğŸ¥ SystÃ¨me de PrÃ©diction du DiabÃ¨te avec Machine Learning

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/)
[![Pandas](https://img.shields.io/badge/Pandas-2.0+-150458.svg)](https://pandas.pydata.org/)
[![Scikit-learn](https://img.shields.io/badge/Scikit--learn-1.3+-F7931E.svg)](https://scikit-learn.org/)
[![Matplotlib](https://img.shields.io/badge/Matplotlib-3.7+-11557c.svg)](https://matplotlib.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

Un systÃ¨me d'analyse et de prÃ©diction du statut diabÃ©tique basÃ© sur les donnÃ©es BRFSS 2015, utilisant plusieurs algorithmes de machine learning pour comparer leurs performances.

## ğŸ“‹ Table des matiÃ¨res

- [PrÃ©sentation](#-prÃ©sentation)
- [FonctionnalitÃ©s](#-fonctionnalitÃ©s)
- [Architecture](#-architecture)
- [Technologies utilisÃ©es](#-technologies-utilisÃ©es)
- [Dataset](#-dataset)
- [Installation](#-installation)
- [Utilisation](#-utilisation)
- [Structure du projet](#-structure-du-projet)
- [ModÃ¨les implÃ©mentÃ©s](#-modÃ¨les-implÃ©mentÃ©s)
- [RÃ©sultats](#-rÃ©sultats)
- [Visualisations](#-visualisations)
- [AmÃ©liorations futures](#-amÃ©liorations-futures)
- [Contribution](#-contribution)
- [Auteur](#-auteur)
- [License](#-license)

## ğŸ¯ PrÃ©sentation

Ce projet a Ã©tÃ© dÃ©veloppÃ© pour analyser les indicateurs de santÃ© binaires du diabÃ¨te Ã  partir des donnÃ©es du **Behavioral Risk Factor Surveillance System (BRFSS)** de 2015. Il implÃ©mente une architecture modulaire permettant de :

- Charger et prÃ©traiter des donnÃ©es de santÃ© Ã  grande Ã©chelle (253 680 observations)
- Visualiser les distributions et relations entre variables de santÃ©
- EntraÃ®ner et comparer 4 modÃ¨les de classification supervisÃ©e
- Ã‰valuer les performances et gÃ©nÃ©rer des rapports dÃ©taillÃ©s

L'objectif principal est de prÃ©dire le statut diabÃ©tique d'un individu en se basant sur 21 variables prÃ©dictives incluant l'Ã¢ge, l'IMC, la pression artÃ©rielle, le cholestÃ©rol, et d'autres indicateurs de santÃ©.

## âœ¨ FonctionnalitÃ©s

### Chargement et exploration des donnÃ©es

- âœ… Chargement automatique du dataset BRFSS 2015
- âœ… Affichage des dimensions (lignes/colonnes)
- âœ… Extraction de la variable cible (`Diabetes_Status`)
- âœ… SÃ©paration des variables prÃ©dictives

### PrÃ©traitement

- ğŸ”§ DÃ©tection automatique des valeurs manquantes
- ğŸ”§ Imputation par la moyenne pour les donnÃ©es numÃ©riques
- ğŸ”§ SÃ©paration train/test (80/20) avec graine alÃ©atoire fixe
- ğŸ”§ Validation des donnÃ©es avant l'entraÃ®nement

### Visualisation des donnÃ©es

- ğŸ“Š Distribution de l'Ã¢ge des participants
- ğŸ“Š Distribution de l'IMC (Indice de Masse Corporelle)
- ğŸ“Š Relation entre l'Ã¢ge et l'IMC (scatter plot)
- ğŸ“Š RÃ©partition diabÃ©tique/non-diabÃ©tique (bar chart)
- ğŸ’¾ Sauvegarde automatique des graphiques en PNG

### ModÃ©lisation et Ã©valuation

- ğŸ¤– EntraÃ®nement de 4 modÃ¨les de classification
- ğŸ“ˆ Ã‰valuation complÃ¨te (accuracy, matrice de confusion, rapport de classification)
- ğŸ† Classement automatique des modÃ¨les par performance
- ğŸ“„ GÃ©nÃ©ration d'un rapport dÃ©taillÃ© au format texte

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              ARCHITECTURE DU SYSTÃˆME ML                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   DataLoader     â”‚  â”€â”€â–º Chargement du CSV
â”‚   (data_loader)  â”‚  â”€â”€â–º Extraction X et y
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Preprocessing   â”‚  â”€â”€â–º Traitement valeurs manquantes
â”‚  (data_preproc.) â”‚  â”€â”€â–º Split train/test (80/20)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                  â”‚
         â–¼                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ DataVisualizer   â”‚  â”‚  ModelTester     â”‚
â”‚ (data_visual.)   â”‚  â”‚  (model_tester)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                     â”‚
         â”‚                     â–¼
         â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚            â”‚   Evaluation     â”‚
         â”‚            â”‚   (modele_eval.) â”‚
         â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                     â”‚
         â–¼                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   figures/       â”‚  â”‚  FileManager     â”‚
â”‚   (4 PNG)        â”‚  â”‚  (file_manager)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                      â”‚  resultats.txt   â”‚
                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Flux de traitement des donnÃ©es

```
CSV (253k lignes)
      â”‚
      â–¼
[DataLoader] â”€â”€â–º X (21 features) + y (target)
      â”‚
      â–¼
[Preprocessing] â”€â”€â–º Nettoyage + Split
      â”‚
      â”œâ”€â”€â”€â”€â”€â–º X_train (80%) â”€â”€â”
      â”‚                       â”‚
      â””â”€â”€â”€â”€â”€â–º X_test (20%)    â”‚
                              â–¼
                    [4 ModÃ¨les ML]
                              â”‚
                              â–¼
                        [Ã‰valuation]
                              â”‚
                              â–¼
                    [Rapport + Classement]
```

## ğŸ› ï¸ Technologies utilisÃ©es

| Technologie | Version | Utilisation |
|------------|---------|-------------|
| **Python** | 3.8+ | Langage principal |
| **Pandas** | 2.0+ | Manipulation des donnÃ©es |
| **Scikit-learn** | 1.3+ | ModÃ¨les ML et mÃ©triques |
| **Matplotlib** | 3.7+ | Visualisation des donnÃ©es |
| **NumPy** | 1.24+ | Calculs numÃ©riques (dÃ©pendance) |

### BibliothÃ¨ques Python dÃ©taillÃ©es

```python
# Manipulation de donnÃ©es
import pandas as pd

# Machine Learning
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn import svm

# MÃ©triques d'Ã©valuation
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

# Visualisation
import matplotlib.pyplot as plt

# SystÃ¨me
import os
```

## ğŸ“Š Dataset

### Source
**BRFSS 2015** (Behavioral Risk Factor Surveillance System)

### CaractÃ©ristiques
- **Observations** : 253 680 individus
- **Variables** : 22 colonnes (21 prÃ©dictives + 1 cible)
- **Variable cible** : `Diabetes_Status` (0 = Non diabÃ©tique, 1 = DiabÃ©tique)

### Variables prÃ©dictives (exemples)

| Variable | Description | Type |
|----------|-------------|------|
| `Age` | CatÃ©gorie d'Ã¢ge | NumÃ©rique (1-13) |
| `BMI` | Indice de Masse Corporelle | NumÃ©rique |
| `HighBP` | Hypertension artÃ©rielle | Binaire (0/1) |
| `HighChol` | CholestÃ©rol Ã©levÃ© | Binaire (0/1) |
| `Smoker` | Statut fumeur | Binaire (0/1) |
| `PhysActivity` | ActivitÃ© physique | Binaire (0/1) |
| `Fruits` | Consommation de fruits | Binaire (0/1) |
| `Veggies` | Consommation de lÃ©gumes | Binaire (0/1) |
| `HvyAlcoholConsump` | Forte consommation d'alcool | Binaire (0/1) |
| `GenHlth` | Ã‰tat de santÃ© gÃ©nÃ©ral | NumÃ©rique (1-5) |
| ... | 11 autres variables | ... |

## ğŸ“¦ Installation

### PrÃ©requis

Assurez-vous d'avoir Python 3.8 ou supÃ©rieur installÃ© :

```bash
python --version
```

### 1. Cloner le dÃ©pÃ´t

```bash
git clone https://github.com/votre-username/diabetes-prediction-ml.git
cd diabetes-prediction-ml
```

### 2. CrÃ©er un environnement virtuel (recommandÃ©)

**Linux/Mac :**
```bash
python3 -m venv venv
source venv/bin/activate
```

**Windows :**
```bash
python -m venv venv
venv\Scripts\activate
```

### 3. Installer les dÃ©pendances

```bash
pip install -r requirements.txt
```

Ou manuellement :

```bash
pip install pandas scikit-learn matplotlib
```

### 4. TÃ©lÃ©charger le dataset

Placez le fichier `diabetes_binary_health_indicators_BRFSS2015.csv` dans le dossier `data/` :

```bash
mkdir -p data
# TÃ©lÃ©chargez le fichier depuis Kaggle ou votre source
# https://www.kaggle.com/datasets/alexteboul/diabetes-health-indicators-dataset
```

### 5. VÃ©rifier l'installation

```bash
python -c "import pandas, sklearn, matplotlib; print('Installation rÃ©ussie!')"
```

## ğŸ’» Utilisation

### Lancement rapide

```bash
python main.py
```

### Utilisation pas Ã  pas

#### 1. Charger les donnÃ©es

```python
from data_loader import DataLoader

loader = DataLoader()
loader.afficher_nb_lignes_colonnes()

# Sortie :
# Nombre des lignes = 253680
# Nombre des colonnes = 22
```

#### 2. Extraire X et y

```python
X = loader.extrait_variables_predicteurs()
y = loader.extrait_variable_explicatif()
```

#### 3. PrÃ©traiter les donnÃ©es

```python
from data_preprocessing import Preprocessing

prep = Preprocessing(X, y)
prep.traitement_des_valeurs_manquantes()
X_train, X_test, y_train, y_test = prep.separation_des_donnees()
```

#### 4. CrÃ©er des visualisations

```python
from data_visualization import DataVisualizer

viz = DataVisualizer(loader.data)
viz.distribution_age()
viz.distribution_imc()
viz.repartition_diabete()
viz.relation_age_imc()
```

#### 5. EntraÃ®ner les modÃ¨les

```python
from model_tester import ModelTester

tester = ModelTester(X_train, X_test, y_train, y_test)
modeles = tester.creer_et_entrainer_tous_modeles()
```

#### 6. Ã‰valuer et comparer

```python
from modele_evaluation import Evaluation

evaluateur = Evaluation(None, X_test)
resultats = evaluateur.evaluer_plusieurs_modeles(modeles, X_test, y_test)
classement = evaluateur.afficher_classement(resultats)
```

#### 7. Sauvegarder les rÃ©sultats

```python
from file_manager import FileManager

gestionnaire = FileManager('resultats.txt')
gestionnaire.sauvegarder_resultats(resultats, classement)
```

## ğŸ“ Structure du projet

```
diabetes-prediction-ml/
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ diabetes_binary_health_indicators_BRFSS2015.csv
â”‚
â”œâ”€â”€ figures/                           # Graphiques gÃ©nÃ©rÃ©s automatiquement
â”‚   â”œâ”€â”€ distribution_age.png           # Histogramme de l'Ã¢ge
â”‚   â”œâ”€â”€ distribution_imc.png           # Histogramme de l'IMC
â”‚   â”œâ”€â”€ relation_age_imc.png           # Scatter plot Ã¢ge/IMC
â”‚   â””â”€â”€ repartition_diabete.png        # Bar chart diabÃ¨te
â”‚
â”œâ”€â”€ data_loader.py                     # Chargement des donnÃ©es
â”‚   â””â”€â”€ class DataLoader
â”‚       â”œâ”€â”€ __init__(chemin)
â”‚       â”œâ”€â”€ afficher_nb_lignes_colonnes()
â”‚       â”œâ”€â”€ extrait_variable_explicatif()
â”‚       â””â”€â”€ extrait_variables_predicteurs()
â”‚
â”œâ”€â”€ data_preprocessing.py              # PrÃ©traitement
â”‚   â””â”€â”€ class Preprocessing
â”‚       â”œâ”€â”€ __init__(X, y)
â”‚       â”œâ”€â”€ verifier_valeurs_manquantes()
â”‚       â”œâ”€â”€ traitement_des_valeurs_manquantes()
â”‚       â””â”€â”€ separation_des_donnees(test_size)
â”‚
â”œâ”€â”€ data_visualization.py              # Visualisations
â”‚   â””â”€â”€ class DataVisualizer
â”‚       â”œâ”€â”€ __init__(data)
â”‚       â”œâ”€â”€ distribution_age()
â”‚       â”œâ”€â”€ distribution_imc()
â”‚       â”œâ”€â”€ relation_age_imc()
â”‚       â””â”€â”€ repartition_diabete()
â”‚
â”œâ”€â”€ model_tester.py                    # EntraÃ®nement des modÃ¨les
â”‚   â””â”€â”€ class ModelTester
â”‚       â”œâ”€â”€ __init__(X_train, X_test, y_train, y_test)
â”‚       â”œâ”€â”€ creer_modele(modele)
â”‚       â””â”€â”€ creer_et_entrainer_tous_modeles()
â”‚
â”œâ”€â”€ modele_evaluation.py               # Ã‰valuation des modÃ¨les
â”‚   â””â”€â”€ class Evaluation
â”‚       â”œâ”€â”€ __init__(modele, X_test)
â”‚       â”œâ”€â”€ evaluer_modele(y_true)
â”‚       â”œâ”€â”€ evaluer_plusieurs_modeles(modeles, X_test, y_test)
â”‚       â””â”€â”€ afficher_classement(resultats)
â”‚
â”œâ”€â”€ file_manager.py                    # Sauvegarde des rÃ©sultats
â”‚   â””â”€â”€ class FileManager
â”‚       â”œâ”€â”€ __init__(nom_fichier)
â”‚       â””â”€â”€ sauvegarder_resultats(resultats, classement)
â”‚
â”œâ”€â”€ main.py                            # Script principal (orchestration)
â”‚
â”œâ”€â”€ requirements.txt                   # DÃ©pendances Python
â”œâ”€â”€ README.md                          # Documentation (ce fichier)
â”œâ”€â”€ LICENSE                            # Licence MIT
â””â”€â”€ resultats.txt                      # Rapport gÃ©nÃ©rÃ© automatiquement
```

## ğŸ¤– ModÃ¨les implÃ©mentÃ©s

### 1. RÃ©gression Logistique
```python
LogisticRegression(max_iter=1000)
```
- **Type** : ModÃ¨le linÃ©aire probabiliste
- **ComplexitÃ©** : O(n Ã— p)
- **Avantages** : Rapide, interprÃ©table, bon pour les relations linÃ©aires
- **InconvÃ©nients** : Assume la linÃ©aritÃ© des donnÃ©es

### 2. Arbre de DÃ©cision
```python
DecisionTreeClassifier()
```
- **Type** : ModÃ¨le basÃ© sur des rÃ¨gles de dÃ©cision
- **ComplexitÃ©** : O(n Ã— log(n) Ã— p)
- **Avantages** : InterprÃ©table, capture les non-linÃ©aritÃ©s
- **InconvÃ©nients** : Risque de surapprentissage

### 3. K-Nearest Neighbors (KNN)
```python
KNeighborsClassifier()
```
- **Type** : Classification par proximitÃ©
- **ComplexitÃ©** : O(n Ã— p) par prÃ©diction
- **Avantages** : Simple, pas d'entraÃ®nement, adaptatif
- **InconvÃ©nients** : Lent en prÃ©diction, sensible Ã  l'Ã©chelle

### 4. Support Vector Machine (SVM)
```python
svm.SVC()
```
- **Type** : SÃ©paration par hyperplan optimal
- **ComplexitÃ©** : O(nÂ² Ã— p) Ã  O(nÂ³ Ã— p)
- **Avantages** : Efficace en haute dimension, robuste
- **InconvÃ©nients** : Lent sur gros datasets, sensible aux paramÃ¨tres

## ğŸ“ˆ RÃ©sultats

### Exemple de sortie console

```
Nombre des lignes = 253680
Nombre des colonnes = 22

EntraÃ®nement des modÃ¨les...
RÃ©gression Logistique Ã©valuÃ© - Accuracy: 0.8542
Arbre de DÃ©cision Ã©valuÃ© - Accuracy: 0.8423
KNN Ã©valuÃ© - Accuracy: 0.8389
SVM Ã©valuÃ© - Accuracy: 0.8501

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘       CLASSEMENT DES MODÃˆLES           â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

1. RÃ©gression Logistique: 0.8542
2. SVM: 0.8501
3. Arbre de DÃ©cision: 0.8423
4. KNN: 0.8389

Fichier crÃ©Ã© avec succÃ¨s : resultats.txt
```

### Structure du fichier `resultats.txt`

```
1. RÃ©gression Logistique: 0.8542
2. SVM: 0.8501
3. Arbre de DÃ©cision: 0.8423
4. KNN: 0.8389

============================================================
RÃ‰SULTATS DÃ‰TAILLÃ‰S
============================================================

RÃ©gression Logistique:
   Accuracy: 0.8542

   Matrice de confusion:
[[38234  4102]
 [ 3275  5125]]

   Rapport:
              precision    recall  f1-score   support

           0       0.92      0.90      0.91     42336
           1       0.56      0.61      0.58      8400

    accuracy                           0.85     50736
   macro avg       0.74      0.76      0.75     50736
weighted avg       0.86      0.85      0.86     50736

[... rÃ©sultats pour les 3 autres modÃ¨les ...]
```

### MÃ©triques expliquÃ©es

| MÃ©trique | Description | Calcul |
|----------|-------------|--------|
| **Accuracy** | Taux de prÃ©dictions correctes | (VP + VN) / Total |
| **Precision** | Proportion de vrais positifs parmi les prÃ©dictions positives | VP / (VP + FP) |
| **Recall** | Proportion de vrais positifs dÃ©tectÃ©s | VP / (VP + FN) |
| **F1-Score** | Moyenne harmonique de precision et recall | 2 Ã— (P Ã— R) / (P + R) |

**Matrice de confusion :**
```
                PrÃ©diction
              NÃ©gatif  Positif
RÃ©el NÃ©gatif    VN       FP
     Positif    FN       VP
```

## ğŸ“Š Visualisations

### 1. Distribution de l'Ã¢ge
![Distribution Age](figures/distribution_age.png)

**Insights** :
- Histogramme montrant la rÃ©partition par catÃ©gorie d'Ã¢ge
- Permet d'identifier les tranches d'Ã¢ge les plus reprÃ©sentÃ©es

### 2. Distribution de l'IMC
![Distribution IMC](figures/distribution_imc.png)

**Insights** :
- Histogramme de l'Indice de Masse Corporelle
- Visualise la prÃ©valence du surpoids/obÃ©sitÃ© dans la population

### 3. Relation Ã‚ge-IMC
![Relation Age IMC](figures/relation_age_imc.png)

**Insights** :
- Scatter plot explorant la corrÃ©lation entre Ã¢ge et IMC
- Aide Ã  dÃ©tecter des patterns non-linÃ©aires

### 4. RÃ©partition du diabÃ¨te
![RÃ©partition DiabÃ¨te](figures/repartition_diabete.png)

**Insights** :
- Bar chart montrant le dÃ©sÃ©quilibre des classes
- Essentiel pour comprendre la mÃ©trique d'accuracy

## ğŸ¨ Personnalisation

### Modifier le chemin du dataset

```python
loader = DataLoader(chemin="./mon_dossier/mon_fichier.csv")
```

### Ajuster la taille du test set

```python
# Par dÃ©faut : 80% train, 20% test
X_train, X_test, y_train, y_test = prep.separation_des_donnees(test_size=0.3)
```

### Changer les paramÃ¨tres des modÃ¨les

```python
# Dans model_tester.py, mÃ©thode creer_modele()

if modele == "logistic_regression":
    return LogisticRegression(
        max_iter=2000,           # Plus d'itÃ©rations
        C=0.5,                   # RÃ©gularisation
        solver='saga'            # Algorithme
    )

elif modele == "decision_tree":
    return DecisionTreeClassifier(
        max_depth=10,            # Profondeur maximale
        min_samples_split=50,    # Ã‰chantillons min pour split
        criterion='entropy'      # CritÃ¨re de split
    )

elif modele == "knn":
    return KNeighborsClassifier(
        n_neighbors=7,           # Nombre de voisins
        weights='distance',      # PondÃ©ration
        metric='manhattan'       # Distance
    )

elif modele == "svm":
    return svm.SVC(
        kernel='rbf',            # Noyau gaussien
        C=1.0,                   # RÃ©gularisation
        gamma='scale'            # ParamÃ¨tre du noyau
    )
```

### Ajouter un nouveau modÃ¨le

```python
# 1. Dans model_tester.py
from sklearn.ensemble import RandomForestClassifier

def creer_modele(self, modele="logistic_regression"):
    # ... code existant ...
    elif modele == "random_forest":
        return RandomForestClassifier(n_estimators=100)

# 2. Dans creer_et_entrainer_tous_modeles()
modeles_liste = ["logistic_regression", "decision_tree", "knn", "svm", "random_forest"]
noms = ["RÃ©gression Logistique", "Arbre de DÃ©cision", "KNN", "SVM", "Random Forest"]
```

### Personnaliser les visualisations

```python
# Dans data_visualization.py

def distribution_age(self):
    plt.figure(figsize=(12, 8))  # Taille du graphique
    plt.hist(
        self.data["Age"],
        bins=30,                  # Nombre de barres
        color="darkblue",         # Couleur
        edgecolor="black",        # Bordure
        alpha=0.7                 # Transparence
    )
    plt.title("Distribution d'Ã¢ge", fontsize=16, fontweight='bold')
    plt.xlabel("Age", fontsize=12)
    plt.ylabel("FrÃ©quence", fontsize=12)
    plt.grid(True, alpha=0.3, linestyle='--')
    plt.savefig("figures/distribution_age.png", dpi=300, bbox_inches='tight')
    plt.show()
```

## ğŸš€ AmÃ©liorations futures

### Court terme (1-2 semaines)

- [ ] Ajouter la validation croisÃ©e (K-Fold)
- [ ] ImplÃ©menter GridSearchCV pour l'optimisation des hyperparamÃ¨tres
- [ ] CrÃ©er un dashboard interactif avec Plotly
- [ ] Ajouter Random Forest et Gradient Boosting
- [ ] GÃ©rer le dÃ©sÃ©quilibre des classes (SMOTE, class_weight)

### Moyen terme (1-2 mois)

- [ ] Interface graphique avec Streamlit ou Tkinter
- [ ] Export des modÃ¨les entraÃ®nÃ©s (pickle/joblib)
- [ ] API REST avec Flask pour prÃ©dictions en temps rÃ©el
- [ ] Analyse des features importantes (SHAP values)
- [ ] Tests unitaires avec pytest

### Long terme (3-6 mois)

- [ ] DÃ©ploiement sur Heroku/AWS
- [ ] Application web complÃ¨te (Django + React)
- [ ] IntÃ©gration de deep learning (TensorFlow/PyTorch)
- [ ] Pipeline MLOps avec MLflow
- [ ] Monitoring des modÃ¨les en production

## ğŸ§ª Tests

### ExÃ©cuter les tests unitaires

```bash
# Installation de pytest
pip install pytest

# Lancer les tests
pytest tests/

# Avec couverture
pytest --cov=. tests/
```

### Exemple de test

```python
# tests/test_data_loader.py
import pytest
from data_loader import DataLoader

def test_chargement_donnees():
    loader = DataLoader()
    assert loader.data is not None
    assert loader.data.shape[0] > 0

def test_extraction_y():
    loader = DataLoader()
    y = loader.extrait_variable_explicatif()
    assert "Diabetes_Status" not in y.name or y.name == "Diabetes_Status"
```

## ğŸ“š Documentation API

### DataLoader

```python
class DataLoader:
    """Charge et prÃ©pare les donnÃ©es du dataset BRFSS 2015."""
    
    def __init__(self, chemin: str = "./data/diabetes_binary_health_indicators_BRFSS2015.csv"):
        """
        Initialise le DataLoader.
        
        Args:
            chemin (str): Chemin vers le fichier CSV
        """
    
    def afficher_nb_lignes_colonnes(self) -> None:
        """Affiche les dimensions du dataset."""
    
    def extrait_variable_explicatif(self, variable_explicatif: str = "Diabetes_Status") -> pd.Series:
        """
        Extrait la variable cible.
        
        Args:
            variable_explicatif (str): Nom de la colonne cible
        
        Returns:
            pd.Series: Variable cible
        """
    
    def extrait_variables_predicteurs(self) -> pd.DataFrame:
        """
        Extrait les variables prÃ©dictives.
        
        Returns:
            pd.DataFrame: DataFrame sans la colonne cible
        """
```

## ğŸ¤ Contribution

Les contributions sont les bienvenues ! Pour contribuer :

### 1. Forker le projet

```bash
git clone https://github.com/votre-username/diabetes-prediction-ml.git
cd diabetes-prediction-ml
```

### 2. CrÃ©er une branche

```bash
git checkout -b feature/amelioration-modeles
```

### 3. Faire vos modifications

- Ajoutez vos changements
- Testez votre code
- Commentez votre code
- Suivez PEP 8 pour le style Python

### 4. Committer et pousser

```bash
git add .
git commit -m "Ajout de la validation croisÃ©e"
git push origin feature/amelioration-modeles
```

### 5. Ouvrir une Pull Request

DÃ©crivez clairement vos modifications et leur intÃ©rÃªt.

### Guidelines de contribution

âœ… **Ã€ faire** :
- Respecter PEP 8
- Ajouter des docstrings
- CrÃ©er des tests unitaires
- Mettre Ã  jour le README si nÃ©cessaire

âŒ **Ã€ Ã©viter** :
- Commits trop volumineux
- Code non testÃ©
- Modifications sans documentation

## ğŸ› Signaler un bug

Si vous trouvez un bug, ouvrez une [issue](https://github.com/votre-username/diabetes-prediction-ml/issues) avec :

1. **Description du bug**
2. **Ã‰tapes pour reproduire**
3. **Comportement attendu**
4. **Comportement actuel**
5. **Screenshots** (si applicable)
6. **Environnement** (OS, version Python, etc.)

## ğŸ’¡ Questions frÃ©quentes (FAQ)

### Q : Le fichier CSV n'est pas trouvÃ©
**R :** Assurez-vous que le fichier est dans `./data/` et que le chemin est correct.

### Q : Erreur d'importation de sklearn
**R :** Installez scikit-learn : `pip install scikit-learn`

### Q : Les graphiques ne s'affichent pas
**R :** VÃ©rifiez que matplotlib est installÃ© et que le dossier `figures/` existe.

### Q : Comment amÃ©liorer les performances des modÃ¨les ?
**R :** Essayez :
- L'optimisation des hyperparamÃ¨tres (GridSearchCV)
- La normalisation des features (StandardScaler)
- L'ingÃ©nierie de features
- Des modÃ¨les d'ensemble (Random Forest, XGBoost)

### Q : Puis-je utiliser ce projet pour d'autres datasets ?
**R :** Oui ! Remplacez le fichier CSV et adaptez les noms de colonnes dans le code.

## ğŸ‘¨â€ğŸ’» Auteur

**Votre Nom**  
Ã‰tudiant en Data Science / Machine Learning

ğŸ“§ [votre.email@example.com](mailto:votre.email@example.com)  
ğŸ”— [LinkedIn](https://linkedin.com/in/votre-profil)  
ğŸ™ [GitHub](https://github.com/votre-username)  
ğŸŒ [Portfolio](https://votre-site.com)

## ğŸ‘¥ Remerciements

- **CDC BRFSS** pour le dataset public
- **Kaggle** pour l'hÃ©bergement des donnÃ©es
- **Scikit-learn** pour les excellentes bibliothÃ¨ques ML
- **CommunautÃ© Python** pour les ressources et tutoriels

## ğŸ“„ License

Ce projet est sous licence MIT - voir le fichier [LICENSE](LICENSE) pour plus de dÃ©tails.

```
MIT License

Copyright (c) 2024 Votre Nom

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction...
```

---

## ğŸ“š Ressources supplÃ©mentaires

### Documentation officielle
- [Pandas Documentation](https://pandas.pydata.org/docs/)
- [Scikit-learn User Guide](https://scikit-learn.org/stable/user_guide.html)
- [Matplotlib Tutorials](https://matplotlib.org/stable/tutorials/index.html)

### Tutoriels recommandÃ©s
- [Machine Learning Mastery](https://machinelearningmastery.com/)
- [Kaggle Learn](https://www.kaggle.com/learn)
- [Real Python ML](https://realpython
